# Repository Implementation Details

This document provides a comprehensive technical overview of the Power Laws & Fractals repositoryâ€”its architecture, multi-platform implementations, and operational testing methodology.

---

## 1. Repository Summary

### Purpose

This repository implements a **cross-platform validation system** for power-law and fractal mathematics. It takes a Single Source of Truth (SSoT) JSON file containing mathematical models of fractal/power-law systems and generates equivalent implementations across three execution environments:

- **Python** (data processing)
- **PostgreSQL** (database with calculated views)
- **Golang** (compiled binary)

Each platform must compute identical derived values from the same input data, and all results are validated against a canonical answer key.

### Core Concept: The Entity Rule Book (ERB)

The SSoT (`ssot/ERB_veritasium-power-laws-and-fractals.json`) follows the CMCC (Computed Measured Calculated Columns) patternâ€”a schema that clearly distinguishes:

| Field Type | Description | Example |
|------------|-------------|---------|
| **Raw** | Direct input values | `Measure`, `Iteration`, `SystemID` |
| **Lookup** | Values retrieved from parent tables | `BaseScale`, `ScaleFactor` |
| **Calculated** | Derived from formulas | `Scale = BaseScale Ã— ScaleFactorPower` |
| **Aggregation** | Rolled up from child tables | `PointCount`, `MinLogScale` |

### Mathematical Domain

The repository models 7 systems from Veritasium's power-law video:

| System | Class | Theoretical Slope |
|--------|-------|-------------------|
| Sierpinski Triangle | Fractal | -1.585 |
| Koch Snowflake | Fractal | -0.262 |
| Zipf Word Frequencies | Power Law | -1.0 |
| Scale-Free Networks | Power Law | -2.5 |
| Sandpile Avalanches | Power Law | -1.0 |
| Earthquake Energies | Power Law | -1.0 |
| Forest Fire Sizes | Power Law | -1.3 |

Each system has 8 data points (iterations 0-7), where the log-log relationship between Scale and Measure should approximate a straight line with the theoretical slope.

---

## 2. Directory Structure

```
ERB_veritasium-power-laws-and-fractals/
â”œâ”€â”€ ssot/                              # Source of Truth
â”‚   â””â”€â”€ ERB_veritasium-power-laws-and-fractals.json
â”‚
â”œâ”€â”€ test-data/                         # Generated test artifacts
â”‚   â”œâ”€â”€ base-data.json                 # Iterations 0-3 (for platform init)
â”‚   â”œâ”€â”€ test-input.json                # Iterations 4-7 (raw facts only)
â”‚   â””â”€â”€ answer-key.json                # All iterations with expected results
â”‚
â”œâ”€â”€ test-results/                      # Platform outputs
â”‚   â”œâ”€â”€ python-results.json
â”‚   â”œâ”€â”€ postgres-results.json
â”‚   â””â”€â”€ golang-results.json
â”‚
â”œâ”€â”€ python/                            # Python implementation
â”‚   â”œâ”€â”€ run-tests.py
â”‚   â”œâ”€â”€ rulebook-to-python.py
â”‚   â””â”€â”€ rulebook/                      # Generated models
â”‚       â”œâ”€â”€ models.py
â”‚       â”œâ”€â”€ data.py
â”‚       â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ postgres/                          # PostgreSQL implementation
â”‚   â”œâ”€â”€ run-tests.py
â”‚   â”œâ”€â”€ 01-drop-and-create-tables.sql
â”‚   â”œâ”€â”€ 02-create-functions.sql
â”‚   â””â”€â”€ 03-create-views.sql
â”‚
â”œâ”€â”€ golang/                            # Go implementation
â”‚   â”œâ”€â”€ run-tests.go
â”‚   â”œâ”€â”€ go.mod
â”‚   â””â”€â”€ pkg/rulebook/
â”‚       â”œâ”€â”€ models.go
â”‚       â”œâ”€â”€ data.go
â”‚       â””â”€â”€ utils.go
â”‚
â”œâ”€â”€ visualizer/                        # Reporting tools
â”‚   â”œâ”€â”€ generate_report.py
â”‚   â”œâ”€â”€ console_output.py
â”‚   â”œâ”€â”€ compare.py
â”‚   â””â”€â”€ report.html
â”‚
â”œâ”€â”€ start.sh                           # Interactive launcher
â”œâ”€â”€ orchestrator.py                    # Test orchestration
â”œâ”€â”€ generate-test-data.py              # Data generation from SSoT
â””â”€â”€ TESTING-PROTOCOL.md
```

---

## 3. Platform Architectures

### 3.1 Python Implementation

**Location:** `python/`

**Architecture:**
- Pure Python with dataclasses for type-safe models
- Lazy calculation pattern (values computed on first access)
- No external dependencies beyond standard library

**Key Components:**

```
python/
â”œâ”€â”€ run-tests.py           # Test runner (entry point)
â”œâ”€â”€ rulebook-to-python.py  # Code generator from SSoT
â””â”€â”€ rulebook/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ models.py          # System, Scale, SystemStats dataclasses
    â”œâ”€â”€ data.py            # Embedded data from SSoT
    â””â”€â”€ utils.py           # Helper functions
```

**Calculation Flow:**

```python
# From models.py - Scale calculation chain
@dataclass
class Scale:
    # Raw fields
    scale_id: str
    system: str
    iteration: int
    measure: float
    
    # Cached computed values (lazy)
    _base_scale: Optional[float] = None
    _scale_factor: Optional[float] = None
    _scale_factor_power: Optional[float] = None
    _scale: Optional[float] = None
    _log_scale: Optional[float] = None
    _log_measure: Optional[float] = None

    def calculate_scale_factor_power(self) -> float:
        """Formula: =POWER(ScaleFactor, Iteration)"""
        if self._scale_factor_power is None:
            self._scale_factor_power = math.pow(self._scale_factor, self.iteration)
        return self._scale_factor_power
```

**Test Protocol:**
1. Load `base-data.json` (systems config + iterations 0-3)
2. Load `test-input.json` (raw facts for iterations 4-7)
3. Compute all derived values using lookup chain
4. Export to `test-results/python-results.json`
5. Validate against `answer-key.json`

---

### 3.2 PostgreSQL Implementation

**Location:** `postgres/`

**Architecture:**
- Normalized tables store only raw data
- SQL functions compute derived values
- Views present "raw + computed" as a unified interface
- Requires PostgreSQL (via Docker or native)

**Key Components:**

```
postgres/
â”œâ”€â”€ run-tests.py                # Python wrapper for psql
â”œâ”€â”€ 01-drop-and-create-tables.sql   # Schema definition
â”œâ”€â”€ 02-create-functions.sql         # Calculation functions (~4000 lines)
â”œâ”€â”€ 03-create-views.sql             # vw_scales, vw_systems, etc.
â”œâ”€â”€ 04-create-policies.sql          # Row-level security (optional)
â””â”€â”€ 05-insert-data.sql              # Seed data from SSoT
```

**Table Schema (normalized):**

```sql
-- systems: Only raw fields stored
CREATE TABLE systems (
  system_id                TEXT PRIMARY KEY,
  display_name             TEXT,
  class                    TEXT,
  base_scale               INTEGER,
  scale_factor             NUMERIC,
  measure_name             TEXT,
  fractal_dimension        NUMERIC,
  theoretical_log_log_slope NUMERIC
);

-- scales: Raw facts only (computed values via views)
CREATE TABLE scales (
  scale_id      TEXT PRIMARY KEY,
  "system"      TEXT,
  iteration     INTEGER,
  measure       NUMERIC,
  is_projected  BOOLEAN
);
```

**Computed Views:**

```sql
-- vw_scales: Raw + all calculated fields
CREATE VIEW vw_scales AS
SELECT 
  s.scale_id,
  s.system,
  s.iteration,
  s.measure,
  -- Lookups from parent system
  sys.base_scale,
  sys.scale_factor,
  -- Calculations
  POWER(sys.scale_factor, s.iteration) AS scale_factor_power,
  sys.base_scale * POWER(sys.scale_factor, s.iteration) AS scale,
  LOG(sys.base_scale * POWER(sys.scale_factor, s.iteration)) AS log_scale,
  LOG(s.measure) AS log_measure,
  s.is_projected
FROM scales s
JOIN systems sys ON s.system = sys.system_id;
```

**Test Protocol:**
1. Initialize schema (run SQL files in order)
2. Insert systems from `base-data.json`
3. Insert base scales (iterations 0-3)
4. Insert test scales (iterations 4-7, raw facts only)
5. Query `vw_scales` to retrieve PostgreSQL-computed values
6. Export to `test-results/postgres-results.json`
7. Validate against `answer-key.json`

---

### 3.3 Golang Implementation

**Location:** `golang/`

**Architecture:**
- Strongly typed structs with pointer-based lazy caching
- Module-based organization (`pkg/rulebook`)
- Single-file test runner with embedded visualization

**Key Components:**

```
golang/
â”œâ”€â”€ run-tests.go          # Entry point (main)
â”œâ”€â”€ go.mod                 # Module definition
â””â”€â”€ pkg/rulebook/
    â”œâ”€â”€ models.go          # System, Scale structs
    â”œâ”€â”€ data.go            # JSON loaders and savers
    â””â”€â”€ utils.go           # Validation helpers
```

**Type Definitions:**

```go
// Scale with lazy-cached computed values
type Scale struct {
    ScaleID     string  `json:"ScaleID"`
    System      string  `json:"System"`
    Iteration   int     `json:"Iteration"`
    Measure     float64 `json:"Measure"`
    IsProjected bool    `json:"IsProjected"`

    // Computed values (nil until calculated)
    baseScale        *float64
    scaleFactor      *float64
    scaleFactorPower *float64
    scale            *float64
    logScale         *float64
    logMeasure       *float64
}

// CalculateAllFields computes all derived values in dependency order
func (s *Scale) CalculateAllFields(systems SystemsMap) {
    s.CalculateBaseScale(systems)    // Lookup
    s.CalculateScaleFactor(systems)  // Lookup
    s.CalculateScaleFactorPower()    // math.Pow(ScaleFactor, Iteration)
    s.CalculateScale()               // BaseScale Ã— ScaleFactorPower
    s.CalculateLogScale()            // math.Log10(Scale)
    s.CalculateLogMeasure()          // math.Log10(Measure)
}
```

**Test Protocol:**
1. Load `base-data.json` via `rulebook.LoadBaseData()`
2. Build systems map: `rulebook.BuildSystemsMap()`
3. Load `test-input.json` via `rulebook.LoadTestInput()`
4. Compute derived values: `scale.CalculateAllFields(systemsMap)`
5. Export to `test-results/golang-results.json`
6. Validate: `rulebook.ValidateAllScales(computed, answerKey)`

---

### 3.4 HTML Visualizer

**Location:** `visualizer/`

**Architecture:**
- Pure Python report generator (no web server)
- Outputs static HTML with embedded Chart.js
- Dark theme with color-coded validation status

**Key Components:**

```
visualizer/
â”œâ”€â”€ generate_report.py     # HTML report generator
â”œâ”€â”€ console_output.py      # Shared ASCII visualization library
â”œâ”€â”€ compare.py             # Cross-platform comparison tool
â”œâ”€â”€ report.html            # Generated output
â””â”€â”€ index.html             # Static dashboard
```

**Report Features:**
- Platform status cards (Python, PostgreSQL, Go)
- Per-system tables with all 8 iterations
- Color coding:
  - ğŸŸ¢ Green = Actual data (iterations 0-3)
  - ğŸŸ£ Purple = Projected/computed (iterations 4-7)
  - ğŸ”´ Red = Validation failures
- Interactive log-log scatter plots with Chart.js
- Theoretical slope lines overlaid

---

## 4. Operational Methodology

### 4.1 The `start.sh` Interactive Launcher

The entry point is a bash script providing a menu-driven interface:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ”º POWER LAWS & FRACTALS - Veritasium Edition         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Run Tests:
  1)  ğŸ§ª  Run ALL Platform Tests   (+ opens report)
  2)  ğŸ  Python Only
  3)  ğŸ¹  Go Only
  4)  ğŸ˜  PostgreSQL Only          (requires Docker)

  View:
  5)  ğŸ“Š  View Results Report      (opens in browser)

  Utilities:
  g)  ğŸ”„  Regenerate Test Data     (CANONICAL Python, 6dp)
  s)  ğŸ“„  View SSoT JSON
  r)  ğŸ“–  View README
  j)  ğŸ““  Jupyter Notebook

  q)  âŒ  Quit
```

**Menu Actions:**

| Option | Action |
|--------|--------|
| `1` | Runs `orchestrator.py --all`, then opens HTML report |
| `2` | Runs `python/run-tests.py` directly |
| `3` | Runs `cd golang && go run .` |
| `4` | Runs `postgres/run-tests.py` (requires psql + Docker) |
| `5` | Generates and opens `visualizer/report.html` |
| `g` | Runs `generate-test-data.py` to rebuild test artifacts |

---

### 4.2 Test Data Generation

**Script:** `generate-test-data.py`

This script reads the SSoT and produces three JSON files:

```
SSoT (ERB_veritasium-power-laws-and-fractals.json)
                    â”‚
                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚               â”‚
    â–¼               â–¼               â–¼
base-data.json  test-input.json  answer-key.json
(iters 0-3)     (iters 4-7)      (all iters)
(all values)    (raw facts only) (all values)
```

**Key Design Decisions:**
- All numeric values rounded to **6 decimal places** for cross-platform consistency
- Base data contains full computed values (platforms don't recompute these)
- Test input contains ONLY raw factsâ€”platforms must compute derived values
- Answer key is the **canonical reference** that all platforms must match

**Data Split:**
- Iterations 0-3: "Actual" data (IsProjected = false)
- Iterations 4-7: "Projected" data (IsProjected = true, tested)

**Measure Generation:**
Uses the power-law relationship to generate synthetic measures:
```python
# log(Measure) = slope Ã— log(Scale) + constant
log_measure = slope * log_scale + constant
measure = 10 ** log_measure
```

---

### 4.3 Test Orchestration

**Script:** `orchestrator.py`

The orchestrator is the central test coordinator:

```bash
# Run all platforms
./orchestrator.py --all

# Run specific platform
./orchestrator.py --platform python

# Regenerate test data first
./orchestrator.py --all --regenerate

# Generate HTML report after tests
./orchestrator.py --all --report
```

**Orchestration Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    orchestrator.py                          â”‚
â”‚                                                             â”‚
â”‚  1. [Optional] Regenerate test data                         â”‚
â”‚     â””â”€â”€ subprocess: python generate-test-data.py            â”‚
â”‚                                                             â”‚
â”‚  2. Run each platform's test runner                         â”‚
â”‚     â”œâ”€â”€ python:   subprocess: python python/run-tests.py    â”‚
â”‚     â”œâ”€â”€ postgres: subprocess: python postgres/run-tests.py  â”‚
â”‚     â””â”€â”€ golang:   subprocess: go run . (from golang/)       â”‚
â”‚                                                             â”‚
â”‚  3. Validate each platform's results                        â”‚
â”‚     â””â”€â”€ Compare test-results/{platform}-results.json        â”‚
â”‚         against test-data/answer-key.json                   â”‚
â”‚                                                             â”‚
â”‚  4. Print summary                                           â”‚
â”‚     â”œâ”€â”€ âœ“ python: 28 scales validated                      â”‚
â”‚     â”œâ”€â”€ âœ“ postgres: 28 scales validated                    â”‚
â”‚     â””â”€â”€ âœ“ golang: 28 scales validated                      â”‚
â”‚                                                             â”‚
â”‚  5. [Optional] Generate HTML report                         â”‚
â”‚     â””â”€â”€ subprocess: python visualizer/generate_report.py    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Validation Logic:**

```python
# Tolerance for floating-point comparison
TOLERANCE = 0.0000015  # Allows for 6dp rounding boundary

# Fields validated for each scale
COMPUTED_FIELDS = [
    'BaseScale',       # Lookup from system
    'ScaleFactor',     # Lookup from system
    'ScaleFactorPower',# POWER(ScaleFactor, Iteration)
    'Scale',           # BaseScale Ã— ScaleFactorPower
    'LogScale',        # LOG10(Scale)
    'LogMeasure'       # LOG10(Measure)
]
```

---

### 4.4 Console Visualization

**Library:** `visualizer/console_output.py`

All three platform runners use this shared library for consistent output:

```
================================================================================
  ğŸ POWER LAWS & FRACTALS - Python Test Runner
================================================================================

All Computed Values (from Python):
  â— Green = Actual Data (iterations 0-3)
  â—Œ Magenta = Projected/Computed (iterations 4-7)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ğŸ”º Sierpinski Triangle
  Theoretical slope: -1.585

  Iter       Measure           Scale     LogScale    LogMeasure        Type
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
     0      1.000000      1.00000000     0.00000       0.00000  â— actual
     1      3.000000      0.50000000    -0.30103       0.47712  â— actual
     2      9.000000      0.25000000    -0.60206       0.95424  â— actual
     3     27.000000      0.12500000    -0.90309       1.43136  â— actual
     4     82.500000      0.06250000    -1.20412       1.91645  â—Œ projected
     5    246.200000      0.03125000    -1.50515       2.39129  â—Œ projected
     6    711.000000      0.01562500    -1.80618       2.85187  â—Œ projected
     7   2225.000000      0.00781250    -2.10721       3.34733  â—Œ projected

  Log-Log Plot:
  log(Measure)
     3.35 â”¤
        â”‚                                        â—Œ
        â”‚                                   â—Œ
        â”‚                              â—Œ
        â”‚                         â—Œ
        â”‚                    â—
        â”‚               â—
        â”‚          â—
        â”‚     â—
     0.00 â”¤â—Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         -2.11                                      0.00
                          log(Scale)
  â— Actual   â—Œ Projected   Â· Theoretical (slope=-1.585)
```

---

### 4.5 HTML Report Generation

**Script:** `visualizer/generate_report.py`

Produces a comprehensive dark-themed HTML report:

**Features:**
- Status banner (ALL PASSED or FAILURES DETECTED)
- Platform status cards (ğŸ Python, ğŸ˜ PostgreSQL, ğŸ¹ Go)
- Per-system sections with:
  - Data tables showing all 8 iterations
  - Expected vs. actual values for each platform
  - Failed values highlighted in red
  - Interactive Chart.js log-log scatter plots
  - Failed points rendered as red X markers

**Sample output structure:**

```html
<div class="status-banner passed">
    âœ“ ALL PLATFORMS PASSED
</div>

<div class="platform-grid">
    <div class="platform-card passed">
        <div class="platform-name">ğŸ Python</div>
        <div class="platform-status passed">âœ“ PASSED</div>
        <div class="platform-counts">28 passed, 0 failed</div>
    </div>
    <!-- ... -->
</div>
```

---

## 5. The Calculation Chain

All three platforms must implement the same calculation chain:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RAW FACTS (Input)                        â”‚
â”‚   ScaleID, System, Iteration, Measure, IsProjected          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LOOKUP (From System)                     â”‚
â”‚   BaseScale â† systems[System].BaseScale                     â”‚
â”‚   ScaleFactor â† systems[System].ScaleFactor                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CALCULATED                               â”‚
â”‚   ScaleFactorPower = ScaleFactor ^ Iteration                â”‚
â”‚   Scale = BaseScale Ã— ScaleFactorPower                      â”‚
â”‚   LogScale = logâ‚â‚€(Scale)                                   â”‚
â”‚   LogMeasure = logâ‚â‚€(Measure)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    OUTPUT (JSON)                            â”‚
â”‚   All values rounded to 6 decimal places                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Running the Tests

### Prerequisites

| Platform | Requirements |
|----------|-------------|
| Python | Python 3.8+ |
| PostgreSQL | `psql` CLI + Docker (or native PostgreSQL) |
| Go | Go 1.21+ |

### Quick Start

```bash
# Make executable
chmod +x start.sh

# Run interactive launcher
./start.sh

# Or run all tests directly
./orchestrator.py --all

# Or run individual platforms
python python/run-tests.py
cd golang && go run .
python postgres/run-tests.py  # Requires PostgreSQL
```

### PostgreSQL Setup (Docker)

```bash
# Start PostgreSQL in Docker
docker run -d -p 5432:5432 \
  -e POSTGRES_HOST_AUTH_METHOD=trust \
  --name power-laws-postgres \
  postgres

# Run tests
python postgres/run-tests.py
```

---

## 7. Key Files Reference

| File | Purpose |
|------|---------|
| `ssot/ERB_*.json` | Source of Truth - defines all data models and schemas |
| `generate-test-data.py` | Creates test artifacts from SSoT |
| `orchestrator.py` | Master test coordinator |
| `start.sh` | Interactive menu launcher |
| `python/run-tests.py` | Python platform test runner |
| `postgres/run-tests.py` | PostgreSQL platform test runner |
| `golang/run-tests.go` | Go platform test runner |
| `visualizer/generate_report.py` | HTML report generator |
| `visualizer/console_output.py` | Shared ASCII visualization |
| `test-data/answer-key.json` | Canonical expected results |

---

## 8. Validation Criteria

A platform **PASSES** when all projected scales (iterations 4-7) match the answer key within tolerance:

- **Tolerance:** 0.0000015 (accounts for 6 decimal place rounding)
- **Fields validated:** BaseScale, ScaleFactor, ScaleFactorPower, Scale, LogScale, LogMeasure
- **Total validated scales:** 28 (7 systems Ã— 4 projected iterations)

A platform **FAILS** if:
- Any computed value differs beyond tolerance
- Results file is not generated
- Scale records are missing
- Execution times out (120s limit)

---

## Summary

This repository demonstrates a practical implementation of the "Single Source of Truth" pattern for mathematical models:

1. **One SSoT** â†’ Multiple equivalent implementations
2. **Automated code generation** for each platform
3. **Unified test protocol** ensuring consistency
4. **Rich visualization** for validation and debugging
5. **Interactive launcher** for easy operation

The architecture ensures that the mathematical truth (power-law relationships, fractal dimensions) is defined once and computed identically across Python, PostgreSQL, and Go.


